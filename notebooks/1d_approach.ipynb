{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 5.863545,
     "end_time": "2020-12-20T18:13:59.855931",
     "exception": false,
     "start_time": "2020-12-20T18:13:53.992386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from typing import Union, List, Dict, Any, cast\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import label_ranking_average_precision_score, accuracy_score\n",
    "import torchvision\n",
    "\n",
    "import audiomentations as audioaa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd \n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "import albumentations as albu\n",
    "from albumentations import pytorch as AT\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import pretrainedmodels\n",
    "#from resnest.torch import resnest50\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import src.audio_augs as aa\n",
    "from src.utils import patch_first_conv\n",
    "from src.loss import lsep_loss_stable, lsep_loss\n",
    "from src.batch_mixer import BatchMixer\n",
    "from src.pann import *\n",
    "\n",
    "import timm\n",
    "from timm.models.resnet import resnet50d\n",
    "from timm.models.efficientnet import tf_efficientnet_b0_ns, tf_efficientnet_lite4, mobilenetv2_140, tf_efficientnet_b1_ns\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.37611,
     "end_time": "2020-12-20T18:14:00.248664",
     "exception": false,
     "start_time": "2020-12-20T18:13:59.872554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_folder_path = \"../data/train/\"\n",
    "train_np_folder_path = \"../data/train_np/\"\n",
    "test_folder_path = \"../data/test/\"\n",
    "sample_submission = \"../data/sample_submission.csv\"\n",
    "train_tp_path = \"../data/train_tp.csv\"\n",
    "train_fp_path = \"../data/train_fp.csv\"\n",
    "train_tp_folds = pd.read_csv(\"../data/train_tp_folds_v3.csv\")\n",
    "train_fp_folds = pd.read_csv(\"train_fp_folds.csv\").drop(\"Unnamed: 0\", 1)\n",
    "\n",
    "train_files = os.listdir(train_folder_path)\n",
    "test_files = os.listdir(test_folder_path)\n",
    "\n",
    "train_tp = pd.read_csv(train_tp_path)\n",
    "train_fp = pd.read_csv(train_fp_path)\n",
    "\n",
    "_df = pd.read_csv(\"missing_3classes_extended.csv\")\n",
    "_df = _df.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "pseudo_hard = pd.read_csv(\"../data/hard_pseudo_227.csv\")\n",
    "pseudo_tp = pd.read_csv(\"../data/tp_pseudo_268.csv\")\n",
    "pseudo_fp = pd.read_csv(\"../data/fp_pseudo_268.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SEED = 25\n",
    "    NUM_BIRDS = 24\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_WORKERS = 4\n",
    "    FOLD = 4\n",
    "    TEST_FOLD = 5\n",
    "    EPOCHS = 50\n",
    "    \n",
    "    #optimizer params\n",
    "    LR = 0.01\n",
    "    LR_ADAM = 1e-3\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    MOMENTUM = 0.9\n",
    "    T_MAX = 8\n",
    "    \n",
    "    #scheduler params\n",
    "    FACTOR = 0.8\n",
    "    PATIENCE = 4\n",
    "\n",
    "    SR = 48000\n",
    "    LENGTH_1  = 10* SR\n",
    "    LENGTH_2 = 5 * SR\n",
    "    #TODO: MAKE AUGS CONF\n",
    "    \n",
    "encoder_params = {\n",
    "    \"efficientnet_b0\": {\n",
    "        #\"features\": 1280,\n",
    "        \"features\": 1792,\n",
    "        #\"features\":2048,\n",
    "        \"init_op\": partial(mobilenetv2_140, pretrained=True, drop_path_rate=0.2)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "model_param = {\n",
    "        'encoder' : 'efficientnet_b0',\n",
    "        'sample_rate': 48000,\n",
    "        'window_size' : 2048, #* 2, # 512 * 2\n",
    "        'hop_size' : 512, #345 * 2, # 320\n",
    "        'mel_bins' : 224, # 60\n",
    "        'fmin' : 80,\n",
    "        'fmax' : 15000,\n",
    "        'classes_num' : 24\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.030754,
     "end_time": "2020-12-20T18:14:00.693737",
     "exception": false,
     "start_time": "2020-12-20T18:14:00.662983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(Config.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSEDModel(nn.Module):\n",
    "    def __init__(self, encoder, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
    "        super().__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 30\n",
    "        self.mixup_coff = Mixup(1.)\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "        \n",
    "        # Model Encoder\n",
    "        self.encoder = encoder_params[encoder][\"init_op\"]()\n",
    "        self.fc1 = nn.Linear(encoder_params[encoder][\"features\"], 1024, bias=True)\n",
    "        self.att_block = AttBlock_V2(1024, classes_num, activation=\"sigmoid\")\n",
    "        self.bn0 = nn.BatchNorm2d(mel_bins)\n",
    "        self.init_weight()\n",
    "    \n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_bn(self.bn0)\n",
    "    \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input : (batch_size, data_length)\"\"\"\n",
    "\n",
    "        x = self.spectrogram_extractor(input)\n",
    "        # batch_size x 1 x time_steps x freq_bins\n",
    "        x = self.logmel_extractor(x)\n",
    "        # batch_size x 1 x time_steps x mel_bins\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        #print(x.shape)\n",
    "\n",
    "        if self.training and False:\n",
    "            x = self.spec_augmenter(x)\n",
    "        \n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        # Output shape (batch size, channels, time, frequency)\n",
    "        x = x.expand(x.shape[0], 3, x.shape[2], x.shape[3])\n",
    "        #print(x.shape)\n",
    "        x = self.encoder.forward_features(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        #print(x.shape)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        #print(x.shape)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "        \n",
    "        framewise_logit = interpolate(segmentwise_logit, self.interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "\n",
    "        return output_dict\n",
    "    \n",
    "def crop_or_pad(y, is_train=True):\n",
    "    length = Config.LENGTH_2\n",
    "    if len(y) < length:\n",
    "        \n",
    "        pad_width = length - len(y)\n",
    "        pad_sub = start = np.random.randint(0, pad_width)\n",
    "        \n",
    "        y = np.pad(y, (pad_sub, pad_width-pad_sub), \"minimum\")\n",
    "    elif len(y) > length:\n",
    "        start = np.random.randint(len(y) - length)\n",
    "        \n",
    "        y = y[start:start + length]\n",
    "\n",
    "    y = y.astype(np.float32, copy=False)\n",
    "    #print(y.shape)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.03189,
     "end_time": "2020-12-20T18:14:00.743201",
     "exception": false,
     "start_time": "2020-12-20T18:14:00.711311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RainforestDataset(Dataset):\n",
    "    def __init__(self, df, audio_transforms = None, image_transforms = None,):\n",
    "        self.audio_transforms = audio_transforms\n",
    "        self.img_transforms = image_transforms\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = copy.deepcopy(self.df.iloc[idx, :].values)\n",
    "        try:\n",
    "            wav = np.load(train_np_folder_path + sample[0] + \".npy\")\n",
    "        except:\n",
    "            wav, sr = librosa.load('../data/test/' + sample[0] + \".flac\", sr=None)\n",
    "            \n",
    "        tmin = float(sample[3]) * Config.SR\n",
    "        tmax = float(sample[5]) * Config.SR\n",
    "        center = np.round((tmin + tmax) / 2)\n",
    "        \n",
    "        multiplier = random.random() * 0.5 + 1\n",
    "        clip_size = (tmax - tmin) * multiplier\n",
    "        beginning = center - Config.LENGTH_2 / 2\n",
    "        if beginning < 0:\n",
    "            beginning = 0\n",
    "            \n",
    "        beginning = np.random.randint( beginning , center)\n",
    "        ending = beginning + Config.LENGTH_2\n",
    "        if ending > len(wav):\n",
    "            ending = len(wav)\n",
    "            beginning = ending - Config.LENGTH_2\n",
    "            \n",
    "        wav_slice = wav[int(beginning):int(ending)]\n",
    "        \n",
    "        beginning_time = beginning / Config.SR\n",
    "        ending_time = ending / Config.SR\n",
    "        recording_id = sample[0]\n",
    "        query_string = f\"recording_id == '{recording_id}' & \"\n",
    "        query_string += f\"t_min < {ending_time} & t_max > {beginning_time}\"\n",
    "        all_tp_events = self.df.query(query_string)\n",
    "\n",
    "        label_array = np.zeros(24, dtype=np.float32)\n",
    "        for species_id in all_tp_events[\"species_id\"].unique():\n",
    "            label_array[int(species_id)] = sample[-1]\n",
    "            #if species_id == 12:\n",
    "            #    label_array[3] = 1\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        #wav_slice = crop_or_pad(wav_slice)\n",
    "       \n",
    "        if self.audio_transforms: # and bird_id not in (3, 7, 8, 9):\n",
    "            wav_slice =  self.audio_transforms(wav_slice)\n",
    "            #wav_slice = self.audio_transforms(samples=wav_slice, sample_rate=Config.SR)\n",
    "            \n",
    "        \n",
    "        #new_sample_rate = 32000\n",
    "        #wav_slice = librosa.resample(wav_slice, Config.SR, new_sample_rate)\n",
    "            \n",
    "        #wav_slice = np.expand_dims(wav_slice, 0).astype(np.float32)\n",
    "        wav_slice = wav_slice.astype(np.float32) * 10.\n",
    "\n",
    "        return torch.tensor(wav_slice), label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.190203,
     "end_time": "2020-12-20T18:14:00.950678",
     "exception": false,
     "start_time": "2020-12-20T18:14:00.760475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 12415 examples\n",
      "Validating on 2766 examples\n"
     ]
    }
   ],
   "source": [
    "train_tp_folds[\"true\"] = 1\n",
    "train_fp_folds[\"true\"] = 0\n",
    "#X_train = train_tp_folds[(train_tp_folds['fold'] != Config.FOLD) & (train_tp_folds['fold'] != Config.TEST_FOLD)].reset_index(drop=True)\n",
    "use_pseudo = True\n",
    "\n",
    "\n",
    "if use_pseudo:\n",
    "    \n",
    "    pseudo_fp_samples = pseudo_fp.sample(n=2000, random_state=Config.SEED)\n",
    "    \n",
    "    pseudo_fp[\"fold\"] = 3\n",
    "    pseudo = pd.concat([pseudo_tp, pseudo_fp_samples], ignore_index=True)\n",
    "    X_train = pseudo[(pseudo['fold'] != Config.FOLD)].reset_index(drop=True)\n",
    "    X_val = pseudo[pseudo['fold'] == Config.FOLD].reset_index(drop=True)\n",
    "    \n",
    "else:\n",
    "    X_train = train_tp_folds[(train_tp_folds['fold'] != Config.FOLD)].reset_index(drop=True)\n",
    "    X_val = train_tp_folds[train_tp_folds['fold'] == Config.FOLD].reset_index(drop=True)\n",
    "#X_test = train_tp_folds[train_tp_folds['fold'] == Config.TEST_FOLD].reset_index(drop=True)\n",
    "#X_train = X_train[~(X_train.species_id == 12)]\n",
    "#X_val = X_val[~(X_val.species_id == 12)]\n",
    "\n",
    "#X_train = train_tp_folds\n",
    "add_dop = False\n",
    "\n",
    "if add_dop:\n",
    "    _df = _df[_df.recording_id.isin(X_train.recording_id)]\n",
    "    X_train = X_train[_df.columns]\n",
    "    X_train = pd.concat([X_train, _df])\n",
    "    \n",
    "X_train = X_train[['recording_id', 'species_id', 'songtype_id', 't_min', 'f_min', 't_max', \"f_max\", \"is_pseudo\"]]\n",
    "X_train[\"label\"] = 1\n",
    "X_train = X_train.fillna(value=1)\n",
    "X_train.loc[X_train.is_pseudo == 1, \"label\"] = 0.85\n",
    "\n",
    "\n",
    "\n",
    "add_pseudo = False\n",
    "\n",
    "if add_pseudo:\n",
    "    X_train = X_train[pseudo_clear.columns]\n",
    "    X_train = pd.concat([X_train, pseudo_clear])\n",
    "\n",
    "print('Training on ' + str(len(X_train)) + ' examples')\n",
    "print('Validating on ' + str(len(X_val)) + ' examples')\n",
    "#print('Testing on ' + str(len(X_test)) + ' examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.031559,
     "end_time": "2020-12-20T18:14:01.049055",
     "exception": false,
     "start_time": "2020-12-20T18:14:01.017496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_transform_train = aa.Compose([\n",
    "  aa.OneOf([\n",
    "    aa.GaussianNoiseSNR(min_snr=5.0, max_snr=20.0),\n",
    "    aa.PinkNoiseSNR( min_snr=5.0, max_snr=20.0,)\n",
    "  ]),\n",
    "  aa.PitchShift(max_steps=4, sr=Config.SR, p=0.2),\n",
    "  #aa.TimeStretch(max_rate=1.2, p=0.1),\n",
    "  aa.TimeShift(sr=Config.SR),\n",
    "  aa.VolumeControl(mode=\"sine\", p=0.2 )\n",
    "])\n",
    "\n",
    "audio_transform = audioaa.Compose([\n",
    "    audioaa.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    audioaa.FrequencyMask(),\n",
    "    audioaa.TimeMask(),\n",
    "    audioaa.AddGaussianSNR(min_SNR=0.001, max_SNR=0.6, p=0.5),\n",
    "    audioaa.PitchShift(min_semitones=-4, max_semitones=4, p=0.2),\n",
    "    audioaa.AddBackgroundNoise(sounds_path=\"../data/noise/\", p= 0.2),\n",
    "    \n",
    "    #|audioaa.Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "    #audioaa.Normalize(),\n",
    "    #audioaa.PolarityInversion(p=0.5),\n",
    "    #audioaa.Gain(min_gain_in_db=-12, max_gain_in_db=12, p=0.5),\n",
    "    #audioaa.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=40, p=0.5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "class PANNsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"clipwise_output\"]\n",
    "        input_ = torch.where(torch.isnan(input_),\n",
    "                             torch.zeros_like(input_),\n",
    "                             input_)\n",
    "        input_ = torch.where(torch.isinf(input_),\n",
    "                             torch.zeros_like(input_),\n",
    "                             input_)\n",
    "\n",
    "        target = target.float()\n",
    "\n",
    "        return self.bce(input_, target)\n",
    "    \n",
    "def soft_focal_loss(input, target, focus=2.0, raw=True, eps=1e-7):\n",
    "\n",
    "    if raw:\n",
    "        input = torch.sigmoid(input)\n",
    "\n",
    "    ranks = input.argsort(dim=-1, descending=True)\n",
    "    mask = torch.ones_like(input)\n",
    "    for i in range(1, 3):\n",
    "        mask[ranks == i] = 0.\n",
    "\n",
    "    prob_true = input * target + (1 - input) * (1 - target)\n",
    "    prob_true = torch.clamp(prob_true, eps, 1-eps)\n",
    "    modulating_factor = (1.0 - prob_true).pow(focus)\n",
    "\n",
    "    return (- modulating_factor * prob_true.log() * mask).mean()\n",
    "        \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, use_coeffs = False, coeffs = None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.coeffs = coeffs\n",
    "        self.use_coeffs = use_coeffs\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        target = target.float()\n",
    "        batch_size = target.shape[0]\n",
    "        max_val = (-logit).clamp(min=0)\n",
    "        loss = logit - logit * target + max_val + \\\n",
    "            ((-max_val).exp() + (-logit - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-logit * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        if self.use_coeffs:\n",
    "            loss = loss * self.coeffs.repeat(batch_size,1)\n",
    "        if len(loss.size()) == 2:\n",
    "            loss = loss.sum(dim=1)\n",
    "\n",
    "        return loss.mean()   \n",
    "\n",
    "class ImprovedPANNsLoss(nn.Module):\n",
    "    def __init__(self, output_key=\"logit\", weights=[1, 1], pos_weights =  None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_key = output_key\n",
    "        if output_key == \"logit\":\n",
    "            self.normal_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "        else:\n",
    "            self.normal_loss = nn.BCELoss()\n",
    "\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[self.output_key]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_output\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = self.normal_loss(input_, target)\n",
    "        auxiliary_loss = self.bce(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss\n",
    "    \n",
    "class ImprovedFocalLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1], use_coeffs = False, coeffs = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.focal = FocalLoss(coeffs=coeffs)\n",
    "        \n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"logit\"]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_logit\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = self.focal(input_, target)\n",
    "        auxiliary_loss = self.focal(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss\n",
    "    \n",
    "    \n",
    "class ImprovedLsep(nn.Module):\n",
    "    def __init__(self, weights=[1, 1]):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        #print(input)\n",
    "    \n",
    "        input_ = input[\"logit\"]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_logit\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = lsep_loss_stable(input_, target)\n",
    "        auxiliary_loss = lsep_loss_stable(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioSEDModel(**model_param)\n",
    "#model.load_state_dict(torch.load('best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 10.752926,
     "end_time": "2020-12-20T18:14:11.820042",
     "exception": false,
     "start_time": "2020-12-20T18:14:01.067116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = RainforestDataset(X_train, audio_transforms=audio_transform_train, image_transforms=None)\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers = Config.NUM_WORKERS, drop_last = True)\n",
    "\n",
    "coeffiicients = np.array([0.25, 0.289, 0.238, 0.508, 0.229, 0.221, 0.212, \n",
    "                          0.285, 0.228, 0.215, 0.218, 0.263, 0.297, 0.216, \n",
    "                          0.247, 0.279, 0.220, 0.218, 0.360, 0.212, 0.215, \n",
    "                          0.221,0.219, 0.240])\n",
    "\n",
    "pos_weights = torch.ones(Config.NUM_BIRDS).cuda()\n",
    "criterion = ImprovedPANNsLoss(pos_weights=pos_weights)\n",
    "\n",
    "criterion_focal = ImprovedFocalLoss()\n",
    "lsep_loss = ImprovedLsep()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LR_ADAM, weight_decay = 0.01)# momentum = 0.9)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=Config.LR, weight_decay=Config.WEIGHT_DECAY, momentum=Config.MOMENTUM)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.8)\n",
    "#scheduler =torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=500, T_mult=1, eta_min=1e-6)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 2, factor = 0.7, mode = \"max\")\n",
    "scheduler =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "mixer = BatchMixer(p=0.5)\n",
    "mixup_augmenter = Mixup(mixup_alpha=1.)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_function = loss_function.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_val_file(record_id, df):\n",
    "\n",
    "    wav = np.load('../data/train_np/' + record_id + \".npy\")\n",
    "        # Split for enough segments to not miss anything\n",
    "        #segments = len(wav) / Config.LENGTH_1\n",
    "        #segments = int(np.ceil(segments))\n",
    "    window = 10 * Config.SR\n",
    "    #stride = 5 * Config.SR\n",
    "    full_length = 60 * Config.SR\n",
    "\n",
    "    mel_array = []\n",
    "    #for i in range(0, full_length + stride - window, stride):\n",
    "    for i in range(0, full_length, window):\n",
    "        \n",
    "            wav_slice = wav[i:i+window]\n",
    "            #new_sample_rate = 32000\n",
    "            #wav_slice = librosa.resample(wav_slice, Config.SR, new_sample_rate)\n",
    "            #wav_slice = np.expand_dims(wav_slice, axis=0).astype(np.float32) \n",
    "            wav_slice = wav_slice.astype(np.float32) * 10.\n",
    "            mel_array.append(wav_slice)\n",
    "        \n",
    "        \n",
    "    val_labels_array = np.zeros(Config.NUM_BIRDS, dtype=np.single)\n",
    "    species_ids = copy.deepcopy(df[(df.recording_id==record_id)].species_id.unique())\n",
    "    val_labels_array[species_ids] = 1.\n",
    "    #if 12 in species_ids:\n",
    "    #    val_labels_array[3] = 1.\n",
    "        \n",
    "    \n",
    "    return np.array(mel_array), val_labels_array\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "    sample_weight = np.sum(truth > 0, axis=1)\n",
    "    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "    overall_lwlrap = label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0,\n",
    "      scores[nonzero_weight_sample_indices, :],\n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "    return overall_lwlrap\n",
    "\n",
    "\n",
    "def validate(model, files_ids, df):\n",
    "        val_loss = []\n",
    "        val_corr = []\n",
    "        val_metrics = []\n",
    "        model.eval()\n",
    "        for i in tqdm(range(0, len(files_ids))):\n",
    "            data, target = load_val_file(files_ids[i], X_val)\n",
    "            data, target = torch.tensor(data), torch.tensor(target)\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda().unsqueeze(0)\n",
    "            output = model(data)\n",
    "            framewise_output = output[\"framewise_logit\"]\n",
    "            output, _ = framewise_output.max(dim=1) \n",
    "            output, _ = torch.max(output, 0)\n",
    "          \n",
    "            output = output.unsqueeze(0)\n",
    "            #print(output.shape)\n",
    "            #loss = loss_function(output, target)\n",
    "            loss = lsep_loss_stable(output, target)\n",
    "            #loss = criterion(output, target)\n",
    "            #loss = 0\n",
    "            \n",
    "            val_metric = lwlrap(target.cpu().detach().numpy(), output.cpu().detach().numpy())\n",
    "            vals, answers = torch.max(output, 1)\n",
    "            vals, targets = torch.max(target, 1)\n",
    "            val_metrics.append(val_metric.item())\n",
    "            corrects = 0\n",
    "            for i in range(0, len(answers)):\n",
    "                if answers[i] == targets[i]:\n",
    "                    corrects = corrects + 1\n",
    "            val_corr.append(corrects)\n",
    "            val_loss.append(loss.item())\n",
    "        valid_epoch_metric = sum(val_metrics) / len(val_loss)\n",
    "\n",
    "        return val_loss, val_corr, valid_epoch_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:53,  2.64it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training end. LR: 0.001, Loss: 4.82452334373228, Correct answers: 5171/12415/train_metric:0.637043949459621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:26<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation end. LR: 0.001, Loss: 2.492921588695155, Correct answers: 84/226, Val metric: 0.8289162340687553\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:39,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training end. LR: 0.0009755527298894294, Loss: 3.474335747995684, Correct answers: 7094/12415/train_metric:0.7816924186419162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation end. LR: 0.0009755527298894294, Loss: 2.3908939129483384, Correct answers: 53/226, Val metric: 0.8229373335794747\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:35,  2.81it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training end. LR: 0.0009046039886902864, Loss: 2.9824891717972295, Correct answers: 7546/12415/train_metric:0.8204587229984315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:37<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 validation end. LR: 0.0009046039886902864, Loss: 2.1517117339952856, Correct answers: 60/226, Val metric: 0.8433822321121962\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:39,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 training end. LR: 0.0007940987335200905, Loss: 2.7101705900315314, Correct answers: 7681/12415/train_metric:0.8365107827378481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 validation end. LR: 0.0007940987335200905, Loss: 2.054140753450647, Correct answers: 74/226, Val metric: 0.8818493828037737\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:37,  2.79it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 training end. LR: 0.0006548539886902864, Loss: 2.420561834150745, Correct answers: 7967/12415/train_metric:0.8553228358043943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 validation end. LR: 0.0006548539886902864, Loss: 2.0381016288183433, Correct answers: 76/226, Val metric: 0.8656358444406385\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:41,  2.75it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 training end. LR: 0.0005005000000000001, Loss: 2.190576592876065, Correct answers: 8003/12415/train_metric:0.8709241363224526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 validation end. LR: 0.0005005000000000001, Loss: 2.0061696208683792, Correct answers: 69/226, Val metric: 0.8717274934479176\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:43,  2.74it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 training end. LR: 0.0003461460113097139, Loss: 1.9984649855859817, Correct answers: 8269/12415/train_metric:0.8831798615453476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 validation end. LR: 0.0003461460113097139, Loss: 1.9468400858144845, Correct answers: 67/226, Val metric: 0.8846851557645352\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:41,  2.75it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 training end. LR: 0.00020690126647990976, Loss: 1.7643275231699789, Correct answers: 8431/12415/train_metric:0.8948647927739994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 validation end. LR: 0.00020690126647990976, Loss: 1.944474306781735, Correct answers: 78/226, Val metric: 0.8940990929896447\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:43,  2.73it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 training end. LR: 9.639601130971382e-05, Loss: 1.6069211937150647, Correct answers: 8524/12415/train_metric:0.9033154142103812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 validation end. LR: 9.639601130971382e-05, Loss: 1.9354987967330797, Correct answers: 66/226, Val metric: 0.8841101474007517\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:41,  2.75it/s]\n",
      "  0%|          | 1/226 [00:00<00:26,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 training end. LR: 2.5447270110570814e-05, Loss: 1.5517114788870658, Correct answers: 8629/12415/train_metric:0.9086091045552349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 validation end. LR: 2.5447270110570814e-05, Loss: 1.9096893821142416, Correct answers: 62/226, Val metric: 0.8906126992826287\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:38,  2.78it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 training end. LR: 1e-06, Loss: 1.5097053579361208, Correct answers: 8565/12415/train_metric:0.9101671212005683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 validation end. LR: 1e-06, Loss: 1.9269978324923895, Correct answers: 62/226, Val metric: 0.8884646850549685\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:47,  2.70it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 training end. LR: 2.5447270110570814e-05, Loss: 1.5187592507177783, Correct answers: 8585/12415/train_metric:0.909870999050855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 validation end. LR: 2.5447270110570814e-05, Loss: 1.9307658229253988, Correct answers: 68/226, Val metric: 0.8935945126906522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.72it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 training end. LR: 9.639601130971413e-05, Loss: 1.5512580563945155, Correct answers: 8507/12415/train_metric:0.9076186621518095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 validation end. LR: 9.639601130971413e-05, Loss: 1.812057024609726, Correct answers: 64/226, Val metric: 0.8993511008787798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:40,  2.76it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 training end. LR: 0.00020690126647991054, Loss: 1.5624504542735316, Correct answers: 8592/12415/train_metric:0.9068963487322488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 validation end. LR: 0.00020690126647991054, Loss: 1.9985739952695054, Correct answers: 65/226, Val metric: 0.8859231161934836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.72it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 training end. LR: 0.0003461460113097153, Loss: 1.6913398758826717, Correct answers: 8487/12415/train_metric:0.8997227251040868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 validation end. LR: 0.0003461460113097153, Loss: 1.914876093906639, Correct answers: 66/226, Val metric: 0.8914819638399554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:44,  2.72it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 training end. LR: 0.0005005000000000021, Loss: 1.8818242252257562, Correct answers: 8389/12415/train_metric:0.8897472553154606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 validation end. LR: 0.0005005000000000021, Loss: 2.0277607440948486, Correct answers: 78/226, Val metric: 0.8741389591692166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:39,  2.77it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 training end. LR: 0.0006548539886902891, Loss: 1.9556587659159015, Correct answers: 8270/12415/train_metric:0.8868740447990761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:47<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 validation end. LR: 0.0006548539886902891, Loss: 2.1291529393829074, Correct answers: 71/226, Val metric: 0.8681212865187937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:43,  2.74it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 training end. LR: 0.0007940987335200938, Loss: 2.064089596579152, Correct answers: 8315/12415/train_metric:0.8796036757479302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 validation end. LR: 0.0007940987335200938, Loss: 1.9072916212335098, Correct answers: 55/226, Val metric: 0.8798090114356998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:38,  2.78it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 training end. LR: 0.0009046039886902903, Loss: 2.0756192231178283, Correct answers: 8167/12415/train_metric:0.8768942004923511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 validation end. LR: 0.0009046039886902903, Loss: 2.0304128617312003, Correct answers: 77/226, Val metric: 0.8774868096434082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:36,  2.80it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 training end. LR: 0.0009755527298894335, Loss: 2.0935554393645255, Correct answers: 8190/12415/train_metric:0.8763208251928009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 validation end. LR: 0.0009755527298894335, Loss: 1.9850751003332898, Correct answers: 68/226, Val metric: 0.889576674616366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:49,  2.68it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 training end. LR: 0.0010000000000000041, Loss: 2.0689009706435666, Correct answers: 8218/12415/train_metric:0.8776142112523153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 validation end. LR: 0.0010000000000000041, Loss: 2.063692388281358, Correct answers: 78/226, Val metric: 0.8692182014139638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:33,  2.83it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 training end. LR: 0.0009755527298894334, Loss: 2.0104563837666665, Correct answers: 8275/12415/train_metric:0.8808319297271924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 validation end. LR: 0.0009755527298894334, Loss: 1.9582361225533274, Correct answers: 88/226, Val metric: 0.88518582716201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:47,  2.70it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 training end. LR: 0.0009046039886902904, Loss: 1.91212434645622, Correct answers: 8351/12415/train_metric:0.8853662705428995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 validation end. LR: 0.0009046039886902904, Loss: 1.9565830167415923, Correct answers: 69/226, Val metric: 0.8795289503332184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:42,  2.74it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 training end. LR: 0.0007940987335200938, Loss: 1.7283028030395509, Correct answers: 8430/12415/train_metric:0.8965041118627208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 validation end. LR: 0.0007940987335200938, Loss: 2.0501531984953756, Correct answers: 76/226, Val metric: 0.8788120060890029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:34,  2.82it/s]\n",
      "  0%|          | 1/226 [00:00<00:22,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 training end. LR: 0.0006548539886902891, Loss: 1.6172161515297427, Correct answers: 8584/12415/train_metric:0.9044168567980354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 validation end. LR: 0.0006548539886902891, Loss: 2.046553440853558, Correct answers: 71/226, Val metric: 0.8903070124669861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.71it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 training end. LR: 0.0005005000000000021, Loss: 1.4855996907141902, Correct answers: 8714/12415/train_metric:0.91089771281408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 validation end. LR: 0.0005005000000000021, Loss: 2.119418817283833, Correct answers: 71/226, Val metric: 0.8801766381249381\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:45,  2.72it/s]\n",
      "  0%|          | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 training end. LR: 0.00034614601130971535, Loss: 1.357074643411944, Correct answers: 8656/12415/train_metric:0.9156062849764427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:29<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 validation end. LR: 0.00034614601130971535, Loss: 1.985338278576336, Correct answers: 75/226, Val metric: 0.8916556895326349\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:40,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 training end. LR: 0.00020690126647991062, Loss: 1.2222883706515835, Correct answers: 8832/12415/train_metric:0.9248794374576355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 validation end. LR: 0.00020690126647991062, Loss: 2.077532095191753, Correct answers: 73/226, Val metric: 0.8951969013645193\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:40,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 training end. LR: 9.639601130971425e-05, Loss: 1.1520200047762164, Correct answers: 8882/12415/train_metric:0.9276633205824376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 validation end. LR: 9.639601130971425e-05, Loss: 2.0254648406948665, Correct answers: 72/226, Val metric: 0.8961716201591439\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:38,  2.78it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 training end. LR: 2.5447270110570967e-05, Loss: 1.0841361925486594, Correct answers: 8978/12415/train_metric:0.932213421122419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 validation end. LR: 2.5447270110570967e-05, Loss: 2.066255928140826, Correct answers: 73/226, Val metric: 0.8961203073554268\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:47,  2.70it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 training end. LR: 1e-06, Loss: 1.0750956148678257, Correct answers: 8897/12415/train_metric:0.932464963163787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 validation end. LR: 1e-06, Loss: 2.1007781387430375, Correct answers: 70/226, Val metric: 0.8942004310523826\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:48,  2.68it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 training end. LR: 2.5447270110570814e-05, Loss: 1.0572171018200536, Correct answers: 8877/12415/train_metric:0.9331106511445678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 validation end. LR: 2.5447270110570814e-05, Loss: 2.0875089485033422, Correct answers: 73/226, Val metric: 0.8944925631001448\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:44,  2.73it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 training end. LR: 9.639601130971386e-05, Loss: 1.0630783533665442, Correct answers: 8940/12415/train_metric:0.9348420763333994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 validation end. LR: 9.639601130971386e-05, Loss: 2.0977960793317947, Correct answers: 66/226, Val metric: 0.8976993037996593\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:39,  2.77it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 training end. LR: 0.00020690126647990997, Loss: 1.0994890101205919, Correct answers: 8825/12415/train_metric:0.931817040623997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 validation end. LR: 0.00020690126647990997, Loss: 2.1542835256694692, Correct answers: 72/226, Val metric: 0.8892765754994685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:39,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 training end. LR: 0.0003461460113097143, Loss: 1.2294149330739053, Correct answers: 8836/12415/train_metric:0.9268733791317499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 validation end. LR: 0.0003461460113097143, Loss: 2.0813389963808313, Correct answers: 66/226, Val metric: 0.8894083893192432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:48,  2.69it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 training end. LR: 0.0005005000000000009, Loss: 1.2872935065530962, Correct answers: 8757/12415/train_metric:0.922857295096101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 validation end. LR: 0.0005005000000000009, Loss: 2.1455529833261946, Correct answers: 89/226, Val metric: 0.8853266512635081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:36,  2.80it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 training end. LR: 0.0006548539886902876, Loss: 1.4186541931667636, Correct answers: 8581/12415/train_metric:0.9128200007378078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 validation end. LR: 0.0006548539886902876, Loss: 2.1605464441586384, Correct answers: 72/226, Val metric: 0.8826325464101668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:51,  2.66it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 training end. LR: 0.0007940987335200921, Loss: 1.5200635308604087, Correct answers: 8582/12415/train_metric:0.9095766394930421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 validation end. LR: 0.0007940987335200921, Loss: 2.0474420733156458, Correct answers: 85/226, Val metric: 0.8858174950652487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:43,  2.74it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 training end. LR: 0.0009046039886902883, Loss: 1.6458690556403128, Correct answers: 8493/12415/train_metric:0.9009518747623237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 validation end. LR: 0.0009046039886902883, Loss: 2.3341251411269197, Correct answers: 66/226, Val metric: 0.865736721353072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:46,  2.71it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 training end. LR: 0.0009755527298894316, Loss: 1.6413901689744765, Correct answers: 8426/12415/train_metric:0.9020798454808936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 validation end. LR: 0.0009755527298894316, Loss: 2.220473658722059, Correct answers: 76/226, Val metric: 0.8816982671986238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:35,  2.81it/s]\n",
      "  0%|          | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 training end. LR: 0.0010000000000000024, Loss: 1.646692199053303, Correct answers: 8495/12415/train_metric:0.9036318501126804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 validation end. LR: 0.0010000000000000024, Loss: 1.9999736262633738, Correct answers: 85/226, Val metric: 0.8907906332756814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:42,  2.74it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 training end. LR: 0.0009755527298894321, Loss: 1.6352423734049644, Correct answers: 8499/12415/train_metric:0.9018589398999893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 validation end. LR: 0.0009755527298894321, Loss: 2.0610372598192335, Correct answers: 65/226, Val metric: 0.8808658985616045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:43,  2.73it/s]\n",
      "  0%|          | 1/226 [00:00<00:26,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 training end. LR: 0.0009046039886902886, Loss: 1.5565747088386166, Correct answers: 8540/12415/train_metric:0.9057054373970894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 validation end. LR: 0.0009046039886902886, Loss: 2.0390716843900427, Correct answers: 90/226, Val metric: 0.883334402405915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:38,  2.79it/s]\n",
      "  0%|          | 1/226 [00:00<00:27,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 training end. LR: 0.0007940987335200926, Loss: 1.4772265680182364, Correct answers: 8700/12415/train_metric:0.911062975399244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 validation end. LR: 0.0007940987335200926, Loss: 2.1336914585754934, Correct answers: 69/226, Val metric: 0.8761405089141298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:48,  2.69it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 training end. LR: 0.0006548539886902891, Loss: 1.3180218724281556, Correct answers: 8701/12415/train_metric:0.9189981601575891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 validation end. LR: 0.0006548539886902891, Loss: 2.150601230891405, Correct answers: 79/226, Val metric: 0.8889247244166556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:41,  2.75it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 training end. LR: 0.0005005000000000015, Loss: 1.2273310175249654, Correct answers: 8729/12415/train_metric:0.9251151671313151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 validation end. LR: 0.0005005000000000015, Loss: 2.156507791671078, Correct answers: 81/226, Val metric: 0.8894096802469791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:47,  2.70it/s]\n",
      "  0%|          | 1/226 [00:00<00:26,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 training end. LR: 0.0003461460113097149, Loss: 1.0838882282280153, Correct answers: 8811/12415/train_metric:0.9319592964823173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:37<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 validation end. LR: 0.0003461460113097149, Loss: 2.1162990616486135, Correct answers: 81/226, Val metric: 0.891841973995319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:42,  2.75it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 training end. LR: 0.00020690126647990968, Loss: 0.9893357729142712, Correct answers: 8969/12415/train_metric:0.9373683604589348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 validation end. LR: 0.00020690126647990968, Loss: 2.1888712760621467, Correct answers: 81/226, Val metric: 0.8936206616265489\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:44,  2.72it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 training end. LR: 9.639601130971415e-05, Loss: 0.9283995743336216, Correct answers: 9087/12415/train_metric:0.9418801509877939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 validation end. LR: 9.639601130971415e-05, Loss: 2.1363469984679098, Correct answers: 79/226, Val metric: 0.8995504543175027\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:48,  2.69it/s]\n",
      "  1%|          | 2/226 [00:00<00:22, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 training end. LR: 2.5447270110571207e-05, Loss: 0.8983135244154161, Correct answers: 9094/12415/train_metric:0.9432807640090417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 validation end. LR: 2.5447270110571207e-05, Loss: 2.1322183440216875, Correct answers: 77/226, Val metric: 0.9013044907403311\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:44,  2.73it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 training end. LR: 1e-06, Loss: 0.8480809907855527, Correct answers: 9064/12415/train_metric:0.9447262279098692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 validation end. LR: 1e-06, Loss: 2.1534402602541762, Correct answers: 77/226, Val metric: 0.8979977629808445\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:47,  2.69it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 training end. LR: 2.5447270110570814e-05, Loss: 0.8737994203644414, Correct answers: 9044/12415/train_metric:0.9433031798679352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 validation end. LR: 2.5447270110570814e-05, Loss: 2.14824210858978, Correct answers: 81/226, Val metric: 0.8982042589896231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:40,  2.76it/s]\n",
      "  0%|          | 1/226 [00:00<00:22,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 training end. LR: 9.63960113097151e-05, Loss: 0.9130358113204279, Correct answers: 8999/12415/train_metric:0.9426122145509479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 validation end. LR: 9.63960113097151e-05, Loss: 2.1629663273296527, Correct answers: 78/226, Val metric: 0.8947957689326116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:36,  2.80it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 training end. LR: 0.00020690126647991342, Loss: 0.914073918865573, Correct answers: 9014/12415/train_metric:0.9407230863396759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 validation end. LR: 0.00020690126647991342, Loss: 2.212163937830292, Correct answers: 77/226, Val metric: 0.8942184645997764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:43,  2.73it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 training end. LR: 0.000346146011309719, Loss: 0.9862238442417114, Correct answers: 8998/12415/train_metric:0.9390174239216832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 validation end. LR: 0.000346146011309719, Loss: 2.111309722461532, Correct answers: 72/226, Val metric: 0.8925989602754706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:38,  2.78it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 training end. LR: 0.0005005000000000086, Loss: 1.0765516342847579, Correct answers: 8905/12415/train_metric:0.9327954618214155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 validation end. LR: 0.0005005000000000086, Loss: 2.3586338980008015, Correct answers: 90/226, Val metric: 0.8836006811805276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:47,  2.69it/s]\n",
      "  0%|          | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 training end. LR: 0.0006548539886902965, Loss: 1.1704868012666703, Correct answers: 8800/12415/train_metric:0.9256001615471415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 validation end. LR: 0.0006548539886902965, Loss: 2.1535642273658144, Correct answers: 70/226, Val metric: 0.8888953221548622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.71it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 training end. LR: 0.0007940987335201021, Loss: 1.3058097012389092, Correct answers: 8754/12415/train_metric:0.9209527108725344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 validation end. LR: 0.0007940987335201021, Loss: 2.0735491039478675, Correct answers: 87/226, Val metric: 0.8919961463817278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:41,  2.76it/s]\n",
      "  0%|          | 1/226 [00:00<00:22,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 training end. LR: 0.0009046039886903006, Loss: 1.385350898734985, Correct answers: 8650/12415/train_metric:0.9155998045093063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 validation end. LR: 0.0009046039886903006, Loss: 2.186882160406197, Correct answers: 79/226, Val metric: 0.8787272002538496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:48,  2.69it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 training end. LR: 0.0009755527298894444, Loss: 1.4027347331277786, Correct answers: 8709/12415/train_metric:0.9140915918546244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:37<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 validation end. LR: 0.0009755527298894444, Loss: 2.3718519970379046, Correct answers: 91/226, Val metric: 0.8629504210038094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:38,  2.78it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 training end. LR: 0.0010000000000000159, Loss: 1.413764071868312, Correct answers: 8636/12415/train_metric:0.9142631053174045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 validation end. LR: 0.0010000000000000159, Loss: 2.002259746062017, Correct answers: 79/226, Val metric: 0.8944347603229008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:44,  2.73it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 training end. LR: 0.0009755527298894445, Loss: 1.3850295092598084, Correct answers: 8655/12415/train_metric:0.9157536860832901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 validation end. LR: 0.0009755527298894445, Loss: 2.0376886245423713, Correct answers: 76/226, Val metric: 0.886698973839853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:39,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 training end. LR: 0.0009046039886903009, Loss: 1.3671940509542342, Correct answers: 8732/12415/train_metric:0.917470962682062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 validation end. LR: 0.0009046039886903009, Loss: 2.162195385029886, Correct answers: 70/226, Val metric: 0.890991139726343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:47,  2.70it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 training end. LR: 0.0007940987335201026, Loss: 1.277372363305861, Correct answers: 8783/12415/train_metric:0.9221200631498192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 validation end. LR: 0.0007940987335201026, Loss: 2.136439568173569, Correct answers: 81/226, Val metric: 0.8846544854675042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:49,  2.68it/s]\n",
      "  0%|          | 1/226 [00:00<00:24,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 training end. LR: 0.000654853988690297, Loss: 1.192944724309829, Correct answers: 8802/12415/train_metric:0.9244717208711432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 validation end. LR: 0.000654853988690297, Loss: 2.1957073718045663, Correct answers: 65/226, Val metric: 0.8905018519593576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.72it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 training end. LR: 0.0005005000000000093, Loss: 1.067007034286376, Correct answers: 8865/12415/train_metric:0.9325112788280882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 validation end. LR: 0.0005005000000000093, Loss: 2.201848338135576, Correct answers: 78/226, Val metric: 0.8906952953961074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:42,  2.74it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 training end. LR: 0.00034614601130971963, Loss: 0.9776597053100986, Correct answers: 9048/12415/train_metric:0.9390884307509311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 validation end. LR: 0.00034614601130971963, Loss: 2.3128028274637407, Correct answers: 75/226, Val metric: 0.8916182078027778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:47,  2.70it/s]\n",
      "  1%|          | 2/226 [00:00<00:21, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 training end. LR: 0.00020690126647991398, Loss: 0.8916314784365316, Correct answers: 9031/12415/train_metric:0.9426270528256151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 validation end. LR: 0.00020690126647991398, Loss: 2.2641257733370352, Correct answers: 80/226, Val metric: 0.8891921657006485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.72it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 training end. LR: 9.639601130971554e-05, Loss: 0.7986888773018314, Correct answers: 9174/12415/train_metric:0.9490983027618612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 validation end. LR: 9.639601130971554e-05, Loss: 2.236720895345232, Correct answers: 78/226, Val metric: 0.8954899691016949\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:39,  2.77it/s]\n",
      "  0%|          | 1/226 [00:00<00:23,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 training end. LR: 2.5447270110571035e-05, Loss: 0.7576799906357642, Correct answers: 9124/12415/train_metric:0.950907918918347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 validation end. LR: 2.5447270110571035e-05, Loss: 2.234369296943192, Correct answers: 74/226, Val metric: 0.8957084983083473\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:37,  2.79it/s]\n",
      "  0%|          | 1/226 [00:00<00:22,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 training end. LR: 1e-06, Loss: 0.7512704860395001, Correct answers: 9120/12415/train_metric:0.9498720058707998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:31<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 validation end. LR: 1e-06, Loss: 2.261326450162229, Correct answers: 73/226, Val metric: 0.8951537669426851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:39,  2.77it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 training end. LR: 2.5447270110570814e-05, Loss: 0.7453123319389359, Correct answers: 9161/12415/train_metric:0.9520514574995509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 validation end. LR: 2.5447270110570814e-05, Loss: 2.266857413064062, Correct answers: 76/226, Val metric: 0.8935484974737251\n",
      "Saving new best model at epoch \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [04:41,  2.76it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 training end. LR: 9.63960113097131e-05, Loss: 0.7756285530569091, Correct answers: 9156/12415/train_metric:0.9492678895336062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 validation end. LR: 9.63960113097131e-05, Loss: 2.2955441833597368, Correct answers: 73/226, Val metric: 0.8951664469115977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:42,  2.75it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 training end. LR: 0.0002069012664799077, Loss: 0.8083265879077296, Correct answers: 9120/12415/train_metric:0.9482400447752438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 validation end. LR: 0.0002069012664799077, Loss: 2.3335679273689744, Correct answers: 78/226, Val metric: 0.8916324290660235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:43,  2.73it/s]\n",
      "  0%|          | 1/226 [00:00<00:26,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 training end. LR: 0.0003461460113097118, Loss: 0.8785748732282269, Correct answers: 9018/12415/train_metric:0.943375730374244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:20<00:00, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 validation end. LR: 0.0003461460113097118, Loss: 2.427501625719324, Correct answers: 89/226, Val metric: 0.8896404219960002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:35,  2.81it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 training end. LR: 0.0005004999999999965, Loss: 0.9486269805796684, Correct answers: 8966/12415/train_metric:0.9401270372788575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:24<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 validation end. LR: 0.0005004999999999965, Loss: 2.3205684307402215, Correct answers: 89/226, Val metric: 0.8878713100950525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:47,  2.70it/s]\n",
      "  0%|          | 1/226 [00:00<00:25,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 training end. LR: 0.000654853988690283, Loss: 1.0605301184135099, Correct answers: 8914/12415/train_metric:0.9343113086467071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:27<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 validation end. LR: 0.000654853988690283, Loss: 2.1562026496482107, Correct answers: 72/226, Val metric: 0.8944443566873292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "775it [04:45,  2.71it/s]\n",
      "  1%|          | 2/226 [00:00<00:20, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 training end. LR: 0.0007940987335200873, Loss: 1.1500512392674722, Correct answers: 8860/12415/train_metric:0.9284123794342074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:34<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 validation end. LR: 0.0007940987335200873, Loss: 2.327410666288528, Correct answers: 65/226, Val metric: 0.8771671733286432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "184it [01:10,  2.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-59ed0e7c938e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Single epoch - train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmixup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_corrects = 0\n",
    "files_ids = copy.deepcopy(X_val.recording_id.unique())\n",
    "mixup=False\n",
    "# Train loop\n",
    "print('Starting training loop')\n",
    "for e in range(0, 150):\n",
    "    # Stats\n",
    "    train_loss = []\n",
    "    train_corr = []\n",
    "    train_metrics = []\n",
    "    \n",
    "    # Single epoch - train\n",
    "    model.train()\n",
    "    for batch, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        data = data.float()\n",
    "        if mixup:\n",
    "            mixup_lambda = torch.tensor(mixup_augmenter.get_lambda(len(data)))\n",
    "            target = do_mixup(target, mixup_lambda)\n",
    "        #data, target = mixer(data, target)\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            if mixup:\n",
    "                mixup_lambda =  mixup_lambda.cuda()\n",
    "\n",
    "        #print(data.shape, target.shape, mixup_lambda.shape)    \n",
    "        optimizer.zero_grad()\n",
    "        if mixup:\n",
    "            output = model(data, mixup_lambda )\n",
    "        else:\n",
    "            output = model(data)\n",
    "        #loss = loss_function(output, target)\n",
    "        \n",
    "        label_smoothing_list = [0.02, 0.015, 0.01]\n",
    "        label_smoothing = random.choice(label_smoothing_list) \n",
    "        targets_smooth = target * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "        \n",
    "        loss = lsep_loss(output, targets_smooth)\n",
    "        #output = output[\"logit\"]\n",
    "        #loss = loss_function(output, targets_smooth)\n",
    "        #loss = lsep_loss(output, target)\n",
    "        framewise_output = output[\"framewise_logit\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "        train_metric = lwlrap(target.cpu().detach().numpy(), clipwise_output_with_max.cpu().detach().numpy())\n",
    "        train_metrics.append(train_metric.item())\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "        # Stats\n",
    "        vals, answers = torch.max(output[\"clipwise_output\"], 1)\n",
    "        vals, targets = torch.max(target, 1)\n",
    "        corrects = 0\n",
    "        for i in range(0, len(answers)):\n",
    "            if answers[i] == targets[i]:\n",
    "                corrects = corrects + 1\n",
    "        train_corr.append(corrects)\n",
    "        train_loss.append(loss.item())\n",
    "        train_epoch_metric = sum(train_metrics) / len(train_loss)\n",
    "    \n",
    "    # Stats\n",
    "    for g in optimizer.param_groups:\n",
    "        lr = g['lr']\n",
    "    print('Epoch ' + str(e) + ' training end. LR: ' + str(lr) + ', Loss: ' + str(sum(train_loss) / len(train_loss)) +\n",
    "          ', Correct answers: ' + str(sum(train_corr)) + '/' + str(train_dataset.__len__()) + '/train_metric:' + str(train_epoch_metric))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "                # Stats\n",
    "        val_loss, val_corr, valid_epoch_metric = validate(model, files_ids, X_val)\n",
    "    # Stats\n",
    "    print('Epoch ' + str(e) + ' validation end. LR: ' + str(lr) + ', Loss: ' + str(sum(val_loss) / len(val_loss)) +\n",
    "          ', Correct answers: ' + str(sum(val_corr)) + '/' + str(len(files_ids)) + \", Val metric: \" + str(valid_epoch_metric))\n",
    "    \n",
    "    # If this epoch is better than previous on validation, save model\n",
    "    # Validation loss is the more common metric, but in this case our loss is misaligned with competition metric, making accuracy a better metric\n",
    "    #valid_epoch_metric = 1 - (sum(train_loss) / len(train_loss))\n",
    "    if train_epoch_metric > best_corrects:\n",
    "        print('Saving new best model at epoch ') #+ str(e) + ' ' + str(sum(val_corr)) + '/' + str(len(files_ids)))\n",
    "        torch.save(model.state_dict(), 'best_model_train.pt')\n",
    "        best_corrects = train_epoch_metric\n",
    "        \n",
    "    # Call every epoch\n",
    "    #scheduler.step(valid_epoch_metric)\n",
    "    scheduler.step()\n",
    "\n",
    "# Free memory\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.192483188822406, Correct answers: 107/227, Val metric: 0.89345172997735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_.pt\"))\n",
    "files_ids = X_val.recording_id.unique()\n",
    "model.cuda()\n",
    "with torch.no_grad():\n",
    "                # Stats\n",
    "        answers_list =  []\n",
    "        targets_list = []\n",
    "        val_loss = []\n",
    "        val_corr = []\n",
    "        val_metrics = []\n",
    "        model.eval()\n",
    "        for i in tqdm(range(0, len(files_ids))):\n",
    "            data, target = load_val_file(files_ids[i], X_val)\n",
    "            data, target = torch.tensor(data), torch.tensor(target)\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda().unsqueeze(0)\n",
    "            output = model(data)\n",
    "            #output = output.squeeze()\n",
    "            framewise_output = output[\"framewise_output\"]\n",
    "            output, _ = framewise_output.max(dim=1) \n",
    "            output, _ = torch.max(output, 0)\n",
    "            #output, _ = torch.max(output[\"clipwise_output\"], 0)\n",
    "            output = output.unsqueeze(0)\n",
    "            #print(output.shape)\n",
    "            loss = lsep_loss_stable(output, target)\n",
    "            val_metric = lwlrap(target.cpu().numpy(), output.cpu().numpy())\n",
    "            vals, answers = torch.max(output, 1)\n",
    "            vals, targets = torch.max(target, 1)\n",
    "            answers_list.append(answers.item())\n",
    "            targets_list.append(targets.item())\n",
    "            val_metrics.append(val_metric.item())\n",
    "            corrects = 0\n",
    "            for i in range(0, len(answers)):\n",
    "                if answers[i] == targets[i]:\n",
    "                    corrects = corrects + 1\n",
    "            val_corr.append(corrects)\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    \n",
    "valid_epoch_metric = sum(val_metrics) / len(val_loss)\n",
    "# Stats\n",
    "print('Loss: ' + str(sum(val_loss) / len(val_loss)) +\n",
    "      ', Correct answers: ' + str(sum(val_corr)) + '/' + str(len(files_ids)) + \", Val metric: \" + str(valid_epoch_metric))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 6), (1, 15), (3, 68), (4, 9), (5, 7), (7, 2), (8, 5), (10, 1), (13, 1), (14, 2), (17, 2), (23, 2)]\n",
      "[(0, 27), (1, 30), (2, 7), (3, 84), (4, 18), (5, 10), (6, 2), (7, 2), (8, 6), (10, 2), (11, 10), (12, 3), (13, 3), (14, 6), (16, 1), (17, 3), (18, 2), (20, 1), (21, 1), (22, 4), (23, 5)]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(len(answers_list)):\n",
    "    if answers_list[i] != targets_list[i]:\n",
    "        errors.append(targets_list[i])\n",
    "        \n",
    "from collections import Counter\n",
    "error_count = sorted(Counter(errors).items(),key = lambda i: i[0])\n",
    "target_count = sorted(Counter(targets_list).items(),key = lambda i: i[0])\n",
    "print(error_count, target_count, sep = \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.995151,
     "end_time": "2020-12-20T18:27:34.774887",
     "exception": false,
     "start_time": "2020-12-20T18:27:33.779736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Already defined above; for reference\n",
    "fft = 2048\n",
    "hop = 512 * 1\n",
    "# Less rounding errors this way\n",
    "sr = 48000\n",
    "length =  10 * sr\n",
    "fmin = 84\n",
    "fmax = 15056\n",
    "\n",
    "\n",
    "def load_test_file(f): \n",
    "    wav, sr = librosa.load('../data/train/' + f, sr=None)\n",
    "\n",
    "        # Split for enough segments to not miss anything\n",
    "    segments = len(wav) / length\n",
    "    segments = int(np.ceil(segments))\n",
    "    \n",
    "    mel_array = []\n",
    "    \n",
    "    for i in range(0, segments):\n",
    "        # Last segment going from the end\n",
    "        if (i + 1) * length > len(wav):\n",
    "            wav_slice = wav[len(wav) - length:len(wav)]\n",
    "        else:\n",
    "            wav_slice = wav[i * length:(i + 1) * length]\n",
    "        #new_sample_rate = 24000\n",
    "        #wav_slice = librosa.resample(slice, Config.SR, new_sample_rate)\n",
    "        #wav_slice = np.expand_dims(wav_slice, axis=0).astype(np.float32) \n",
    "        wav_slice = wav_slice.astype(np.float32) \n",
    "        mel_array.append(wav_slice)\n",
    "    \n",
    "    return np.array(mel_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioSEDModel(**model_param)\n",
    "model.load_state_dict(torch.load(f\"best_model_0_pseudo_resnet50.pt\"))\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "PERIOD = 10\n",
    "global_time = 0.0\n",
    "threshold = 0.1\n",
    "estimated_event_list = []\n",
    "\n",
    "test_files = train_files\n",
    "\n",
    "for i in range(0, len(test_files)):\n",
    "    global_time = 0.0\n",
    "    data = load_test_file(test_files[i])\n",
    "    file_id = str.split(test_files[i], '.')[0]\n",
    "    for part in data:\n",
    "    \n",
    "        part = torch.tensor(part).unsqueeze(0)\n",
    "        part = part.float()\n",
    "        if torch.cuda.is_available():\n",
    "            part = part.cuda()\n",
    "\n",
    "        output = model(part)\n",
    "\n",
    "        framewise_outputs = output[\"framewise_output\"].detach().cpu().numpy()[0]\n",
    "\n",
    "        thresholded = framewise_outputs >= threshold\n",
    "\n",
    "        #print(thresholded)\n",
    "        #print(thresholded.shape)\n",
    "\n",
    "        for target_idx in range(thresholded.shape[1]):\n",
    "            if thresholded[:, target_idx].mean() == 0:\n",
    "                pass\n",
    "            else:\n",
    "                detected = np.argwhere(thresholded[:, target_idx]).reshape(-1)\n",
    "                head_idx = 0\n",
    "                tail_idx = 0\n",
    "                while True:\n",
    "                    if (tail_idx + 1 == len(detected)) or (detected[tail_idx + 1] - detected[tail_idx] != 1):\n",
    "                        onset = 0.01 * detected[head_idx] + global_time\n",
    "                        offset = 0.01 * detected[tail_idx] + global_time\n",
    "                        onset_idx = detected[head_idx]\n",
    "                        offset_idx = detected[tail_idx]\n",
    "                        max_confidence = framewise_outputs[onset_idx:offset_idx, target_idx].max()\n",
    "                        mean_confidence = framewise_outputs[onset_idx:offset_idx, target_idx].mean()\n",
    "                        estimated_event = {\n",
    "                            \"file_id\": file_id,\n",
    "                            \"species_id\": target_idx,\n",
    "                            \"onset\": onset,\n",
    "                            \"offset\": offset,\n",
    "                            \"max_confidence\": max_confidence,\n",
    "                            \"mean_confidence\": mean_confidence\n",
    "                        }\n",
    "                        estimated_event_list.append(estimated_event)\n",
    "                        head_idx = tail_idx + 1\n",
    "                        tail_idx = tail_idx + 1\n",
    "                        if head_idx >= len(detected):\n",
    "                            break\n",
    "                    else:\n",
    "                        tail_idx += 1\n",
    "\n",
    "        global_time += PERIOD\n",
    "\n",
    "prediction_df = pd.DataFrame(estimated_event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4718"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_df.file_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(\"pseudolabels_raw_sed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
    "                               's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.read_csv(\"pseudolabels_raw_sed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_df.file_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_df = pd.read_csv(\"pseudolabels_raw_fold1.csv\")\n",
    "for file_id, sub_df in prediction_df.groupby(\"file_id\"):\n",
    "    events = sub_df[[\"file_id\", \"species_id\", \"onset\", \"offset\", \"max_confidence\", ]]\n",
    "    sub_row = []\n",
    "    recording_id = events.file_id.unique()[0]\n",
    "    sub_row.append(recording_id)\n",
    "    unique = events.species_id.unique()\n",
    "    label_array = np.zeros(24, dtype=np.float32)\n",
    "    for i in unique:\n",
    "        pred_proba = events[events.species_id==i].max_confidence.max()\n",
    "\n",
    "        label_array[int(i)] = pred_proba \n",
    "    sub_row.extend(list(label_array))\n",
    "    sub_series = pd.Series(sub_row, index = submission.columns)\n",
    "    submission = submission.append(sub_series, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1992, 25)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"test_submission_from_frames.csv\", index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "duration": 1833.679699,
   "end_time": "2020-12-20T18:44:03.770668",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-20T18:13:30.090969",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f15442e94a44248b50672c2777030c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c435759345342aebeb8f5670af57f75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e56ad2e6997c43d695706f19b3c85f92",
       "placeholder": "​",
       "style": "IPY_MODEL_0f15442e94a44248b50672c2777030c9",
       "value": " 105M/105M [00:05&lt;00:00, 22.0MB/s]"
      }
     },
     "8b8ab01ab9604583ae4dbf53f3058ecf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0f16c2b57ec45a0a100f1e728ab3d50",
       "max": 110273258,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_98b001f4de7143579e81c44054c3e04c",
       "value": 110273258
      }
     },
     "98b001f4de7143579e81c44054c3e04c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c71fd161194b4e9d8f6df0c22ddc66c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0f16c2b57ec45a0a100f1e728ab3d50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e56ad2e6997c43d695706f19b3c85f92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff6567e773d44b348f8b0ef7a4cf61e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8b8ab01ab9604583ae4dbf53f3058ecf",
        "IPY_MODEL_4c435759345342aebeb8f5670af57f75"
       ],
       "layout": "IPY_MODEL_c71fd161194b4e9d8f6df0c22ddc66c2"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
