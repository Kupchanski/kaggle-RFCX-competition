{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from typing import Union, List, Dict, Any, cast\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd \n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "import albumentations as albu\n",
    "from albumentations import pytorch as AT\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "import pretrainedmodels\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.utils import patch_first_conv\n",
    "from src.pann import *\n",
    "\n",
    "import timm\n",
    "from timm.models.efficientnet import tf_efficientnet_b0_ns, mobilenetv2_100, mobilenetv2_110d, mobilenetv2_140, tf_efficientnet_lite4\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "train_folder_path = \"../data/train/\"\n",
    "train_np_folder_path = \"../data/train_np/\"\n",
    "test_folder_path = \"../data/test/\"\n",
    "sample_submission = \"../data/sample_submission.csv\"\n",
    "train_tp_path = \"../data/train_tp.csv\"\n",
    "train_fp_path = \"../data/train_fp.csv\"\n",
    "train_tp_folds = pd.read_csv(\"../data/train_tp_folds_v3.csv\")\n",
    "train_fp_folds = pd.read_csv(\"train_fp_folds.csv\").drop(\"Unnamed: 0\", 1)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    SEED = 17\n",
    "    NUM_BIRDS = 24\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_WORKERS = 4\n",
    "    FOLD = 4\n",
    "    TEST_FOLD = 5\n",
    "    EPOCHS = 50\n",
    "    \n",
    "    #optimizer params\n",
    "    LR = 0.01\n",
    "    LR_ADAM = 1e-3\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    MOMENTUM = 0.9\n",
    "    T_MAX = 8\n",
    "    \n",
    "    #scheduler params\n",
    "    FACTOR = 0.8\n",
    "    PATIENCE = 4\n",
    "\n",
    "    SR = 48000\n",
    "    LENGTH_1  = 10* SR\n",
    "    LENGTH_2 = 5 * SR\n",
    "    #TODO: MAKE AUGS CONF\n",
    "    \n",
    "encoder_params = {\n",
    "    \"efficientnet_b0\": {\n",
    "        #\"features\": 1280,\n",
    "        \"features\": 1792,\n",
    "        \"init_op\": partial(mobilenetv2_140, pretrained=True, drop_path_rate=0.2)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "model_param = {\n",
    "        'encoder' : 'efficientnet_b0',\n",
    "        'sample_rate': 48000,\n",
    "        'window_size' : 2048, #* 2, # 512 * 2\n",
    "        'hop_size' : 512, #345 * 2, # 320\n",
    "        'mel_bins' : 224, # 60\n",
    "        'fmin' : 50,\n",
    "        'fmax' : 15000,\n",
    "        'classes_num' : 24\n",
    "    }\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(Config.SEED)\n",
    "\n",
    "class AudioSEDModel(nn.Module):\n",
    "    def __init__(self, encoder, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
    "        super().__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 30  # Downsampled ratio\n",
    "        self.mixup_coff = Mixup(1.)\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "        \n",
    "        # Model Encoder\n",
    "        self.encoder = encoder_params[encoder][\"init_op\"]()\n",
    "        self.fc1 = nn.Linear(encoder_params[encoder][\"features\"], 1024, bias=True)\n",
    "        self.att_block = AttBlock(1024, classes_num, activation=\"sigmoid\")\n",
    "        self.bn0 = nn.BatchNorm2d(mel_bins)\n",
    "        self.init_weight()\n",
    "    \n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_bn(self.bn0)\n",
    "    \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input : (batch_size, data_length)\"\"\"\n",
    "\n",
    "        x = self.spectrogram_extractor(input)\n",
    "        # batch_size x 1 x time_steps x freq_bins\n",
    "        x = self.logmel_extractor(x)\n",
    "        # batch_size x 1 x time_steps x mel_bins\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        #print(x.shape)\n",
    "\n",
    "        if self.training and False:\n",
    "            x = self.spec_augmenter(x)\n",
    "        \n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        # Output shape (batch size, channels, time, frequency)\n",
    "        x = x.expand(x.shape[0], 3, x.shape[2], x.shape[3])\n",
    "        #print(x.shape)\n",
    "        x = self.encoder.forward_features(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        #print(x.shape)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        #print(x.shape)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "        \n",
    "        framewise_logit = interpolate(segmentwise_logit, self.interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "\n",
    "        return output_dict\n",
    "    \n",
    "def crop_or_pad(y, is_train=True):\n",
    "    length = Config.LENGTH_2\n",
    "    if len(y) < length:\n",
    "        \n",
    "        pad_width = length - len(y)\n",
    "        pad_sub = start = np.random.randint(0, pad_width)\n",
    "        \n",
    "        y = np.pad(y, (pad_sub, pad_width-pad_sub), \"minimum\")\n",
    "    elif len(y) > length:\n",
    "        start = np.random.randint(len(y) - length)\n",
    "        \n",
    "        y = y[start:start + length]\n",
    "\n",
    "    y = y.astype(np.float32, copy=False)\n",
    "    #print(y.shape)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction loop\n",
      "1992\n",
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n",
      "Starting prediction loop\n",
      "1992\n",
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n",
      "Starting prediction loop\n",
      "1992\n",
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n",
      "Starting prediction loop\n",
      "1992\n",
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n",
      "Starting prediction loop\n",
      "1992\n",
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n"
     ]
    }
   ],
   "source": [
    "def load_test_file(f, win_size = 5): \n",
    "    wav, sr = librosa.load('../data/test/' + f, sr=None )\n",
    "\n",
    "    # Split for enough segments to not miss anything\n",
    "    window = win_size * Config.SR\n",
    "    stride = 5 * Config.SR\n",
    "    full_length = 60 * Config.SR\n",
    "    \n",
    "    mel_array = []\n",
    "    for i in range(0, full_length, window):\n",
    "    #for i in range(0, full_length + stride - window, stride):\n",
    "        \n",
    "        wav_slice = wav[i:i+window]\n",
    "        #new_sample_rate = 24000\n",
    "        #wav_slice = librosa.resample(slice, Config.SR, new_sample_rate)\n",
    "        #wav_slice = np.expand_dims(wav_slice, axis=0).astype(np.float32) \n",
    "        wav_slice = wav_slice.astype(np.float32) * 10.\n",
    "        mel_array.append(wav_slice)\n",
    "    \n",
    "    return np.array(mel_array)\n",
    "\n",
    "model = AudioSEDModel(**model_param)\n",
    "#model.load_state_dict(torch.load(f\"best_model_{Config.FOLD}.pt\"))\n",
    "model.load_state_dict(torch.load(f\"best_model_only_train.pt\"))\n",
    "\n",
    "use_cuda = True\n",
    "\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.eval()\n",
    "# Prediction loop\n",
    "TTA = [5,10,20,30,60]\n",
    "\n",
    "for length in TTA:\n",
    "    print('Starting prediction loop')\n",
    "    with open(f'submission_{Config.FOLD}{length}.csv', 'w', newline='') as csvfile:\n",
    "        submission_writer = csv.writer(csvfile, delimiter=',')\n",
    "        submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
    "                                   's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n",
    "\n",
    "        test_files = os.listdir('../data/test/')\n",
    "        print(len(test_files))\n",
    "\n",
    "        # Every test file is split on several chunks and prediction is made for each chunk\n",
    "        for i in range(0, len(test_files)):\n",
    "            data = load_test_file(test_files[i], win_size = length)\n",
    "            data = torch.tensor(data)\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                data = data.cuda()\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            # Taking max prediction from all slices per bird species\n",
    "            # Usually you want Sigmoid layer here to convert output to probabilities\n",
    "            # In this competition only relative ranking matters, and not the exact value of prediction, so we can use it directly\n",
    "\n",
    "            framewise_output = output[\"framewise_output\"]\n",
    "            output, _ = framewise_output.max(dim=1) \n",
    "            maxed_output = torch.max(output, dim=0)[0]\n",
    "            #maxed_output = torch.max(output[\"clipwise_output\"], dim=0)[0]\n",
    "            maxed_output = maxed_output.cpu().detach()\n",
    "\n",
    "            file_id = str.split(test_files[i], '.')[0]\n",
    "            write_array = [file_id]\n",
    "\n",
    "            for out in maxed_output:\n",
    "                write_array.append(out.item())\n",
    "\n",
    "            submission_writer.writerow(write_array)\n",
    "\n",
    "            if i % 100 == 0 and i > 0:\n",
    "                print('Predicted for ' + str(i) + ' of ' + str(len(test_files) + 1) + ' files')\n",
    "\n",
    "    print('Submission generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv(f\"submission_{Config.FOLD}5.csv\")\n",
    "sub2 = pd.read_csv(f\"submission_{Config.FOLD}10.csv\")\n",
    "sub3 = pd.read_csv(f\"submission_{Config.FOLD}20.csv\")\n",
    "sub4 = pd.read_csv(f\"submission_{Config.FOLD}30.csv\")\n",
    "sub5 = pd.read_csv(f\"submission_{Config.FOLD}60.csv\")\n",
    "\n",
    "\n",
    "BLEND=sub1.copy() \n",
    "BLEND.iloc[:,1:] = sub1.iloc[:,1:] +sub2.iloc[:,1:] +sub3.iloc[:,1:] +sub4.iloc[:,1:] +sub5.iloc[:,1:] \n",
    "BLEND.to_csv(f\"submission_{Config.FOLD}_TTA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"submission_4_TTA_calibrated.csv\")\n",
    "#df =BLEND\n",
    "a = df.iloc[:, 1:].to_numpy()\n",
    "plt.hist(a.argmax(axis=1), bins=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"submission_4_TTA.csv\")\n",
    "coeffiicients = np.array([0.25, 0.289, 0.238, 0.508, 0.229, 0.221, 0.212, \n",
    "                          0.285, 0.228, 0.215, 0.218, 0.263, 0.297, 0.216, \n",
    "                          0.247, 0.279, 0.220, 0.218, 0.360, 0.212, 0.215, \n",
    "                          0.221,0.219, 0.240])\n",
    "df.iloc[:, 1] = df.iloc[:, 1] * coeffiicients[0] \n",
    "df.iloc[:, 2] = df.iloc[:, 2] * coeffiicients[1] * 1.5\n",
    "df.iloc[:, 3] = df.iloc[:, 3] * coeffiicients[2] \n",
    "df.iloc[:, 4] = df.iloc[:, 4] * coeffiicients[3]\n",
    "df.iloc[:, 5] = df.iloc[:, 5] * coeffiicients[4]\n",
    "df.iloc[:, 6] = df.iloc[:, 6] * coeffiicients[5]\n",
    "df.iloc[:, 7] = df.iloc[:, 7] * coeffiicients[6]\n",
    "df.iloc[:, 8] = df.iloc[:, 8] * coeffiicients[7] \n",
    "df.iloc[:, 9] = df.iloc[:, 9] * coeffiicients[8]\n",
    "df.iloc[:, 10] = df.iloc[:, 10] * coeffiicients[9]\n",
    "df.iloc[:, 11] = df.iloc[:, 11] * coeffiicients[10]\n",
    "df.iloc[:, 12] = df.iloc[:, 12] * coeffiicients[11]\n",
    "df.iloc[:, 13] = df.iloc[:, 13] * coeffiicients[12]\n",
    "df.iloc[:, 14] = df.iloc[:, 14] * coeffiicients[13]\n",
    "df.iloc[:, 15] = df.iloc[:, 15] * coeffiicients[14]\n",
    "df.iloc[:, 16] = df.iloc[:, 16] * coeffiicients[15]\n",
    "df.iloc[:, 17] = df.iloc[:, 17] * coeffiicients[16]\n",
    "df.iloc[:, 18] = df.iloc[:, 18] * coeffiicients[17]\n",
    "df.iloc[:, 19] = df.iloc[:, 19] * coeffiicients[18] * 2.5\n",
    "df.iloc[:, 20] = df.iloc[:, 20] * coeffiicients[19]\n",
    "df.iloc[:, 21] = df.iloc[:, 21] * coeffiicients[20]\n",
    "df.iloc[:, 22] = df.iloc[:, 22] * coeffiicients[21]\n",
    "df.iloc[:, 23] = df.iloc[:, 23] * coeffiicients[22]\n",
    "df.iloc[:, 24] = df.iloc[:, 24] * coeffiicients[23]\n",
    "#df.s20 = -10\n",
    "#df.s22 = -10\n",
    "df.to_csv(\"submission_4_TTA_calibrated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv(f\"submission_mobnet_framewise_0_TTA.csv\")\n",
    "sub2 = pd.read_csv(f\"submission_mobnet_framewise_1_TTA.csv\")\n",
    "sub3 = pd.read_csv(f\"submission_mobnet_framewise_2_TTA.csv\")\n",
    "sub4 = pd.read_csv(f\"submission_mobnet_framewise_3_TTA.csv\")\n",
    "sub5 = pd.read_csv(f\"submission_mobnet_framewise_4_TTA.csv\")\n",
    "#sub6 = pd.read_csv(f\"submission_sed_framewise_5_TTA.csv\")\n",
    "\n",
    "\n",
    "BLEND=sub1.copy() \n",
    "BLEND.iloc[:,1:] = sub1.iloc[:,1:] +sub2.iloc[:,1:] +sub3.iloc[:,1:] +sub4.iloc[:,1:] +sub5.iloc[:,1:] #+sub6.iloc[:,1:] \n",
    "BLEND.to_csv(f\"submission_sed_mobnet_framewise_TTA_ens.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
